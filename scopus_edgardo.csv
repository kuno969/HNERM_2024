"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Abstract","Document Type","Publication Stage","Open Access","Source","EID"
"Jonsson T.","Jonsson, Thorin (36984172600)","36984172600","Micro-CT and deep learning: Modern techniques and applications in insect morphology and neuroscience","2023","Frontiers in Insect Science","3","","1016277","","","","0","10.3389/finsc.2023.1016277","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168112511&doi=10.3389%2ffinsc.2023.1016277&partnerID=40&md5=b0916b9afae98ceb5286d9adc7bdbb52","Advances in modern imaging and computer technologies have led to a steady rise in the use of micro-computed tomography (µCT) in many biological areas. In zoological research, this fast and non-destructive method for producing high-resolution, two- and three-dimensional images is increasingly being used for the functional analysis of the external and internal anatomy of animals. µCT is hereby no longer limited to the analysis of specific biological tissues in a medical or preclinical context but can be combined with a variety of contrast agents to study form and function of all kinds of tissues and species, from mammals and reptiles to fish and microscopic invertebrates. Concurrently, advances in the field of artificial intelligence, especially in deep learning, have revolutionised computer vision and facilitated the automatic, fast and ever more accurate analysis of two- and three-dimensional image datasets. Here, I want to give a brief overview of both micro-computed tomography and deep learning and present their recent applications, especially within the field of insect science. Furthermore, the combination of both approaches to investigate neural tissues and the resulting potential for the analysis of insect sensory systems, from receptor structures via neuronal pathways to the brain, are discussed. Copyright © 2023 Jonsson.","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85168112511"
"Iuga A.-I.; Carolus H.; Höink A.J.; Brosch T.; Klinder T.; Maintz D.; Persigehl T.; Baeßler B.; Püsken M.","Iuga, Andra-Iza (57194724957); Carolus, Heike (56460339900); Höink, Anna J. (14015932800); Brosch, Tom (55892057300); Klinder, Tobias (23469854800); Maintz, David (7003929179); Persigehl, Thorsten (22935472200); Baeßler, Bettina (56310147700); Püsken, Michael (24333286000)","57194724957; 56460339900; 14015932800; 55892057300; 23469854800; 7003929179; 22935472200; 56310147700; 24333286000","Automated detection and segmentation of thoracic lymph nodes from CT using 3D foveal fully convolutional neural networks","2021","BMC Medical Imaging","21","1","69","","","","16","10.1186/s12880-021-00599-z","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104291492&doi=10.1186%2fs12880-021-00599-z&partnerID=40&md5=8d5aea935cafcc7952db8717aba2ce40","Background: In oncology, the correct determination of nodal metastatic disease is essential for patient management, as patient treatment and prognosis are closely linked to the stage of the disease. The aim of the study was to develop a tool for automatic 3D detection and segmentation of lymph nodes (LNs) in computed tomography (CT) scans of the thorax using a fully convolutional neural network based on 3D foveal patches. Methods: The training dataset was collected from the Computed Tomography Lymph Nodes Collection of the Cancer Imaging Archive, containing 89 contrast-enhanced CT scans of the thorax. A total number of 4275 LNs was segmented semi-automatically by a radiologist, assessing the entire 3D volume of the LNs. Using this data, a fully convolutional neuronal network based on 3D foveal patches was trained with fourfold cross-validation. Testing was performed on an unseen dataset containing 15 contrast-enhanced CT scans of patients who were referred upon suspicion or for staging of bronchial carcinoma. Results: The algorithm achieved a good overall performance with a total detection rate of 76.9% for enlarged LNs during fourfold cross-validation in the training dataset with 10.3 false-positives per volume and of 69.9% in the unseen testing dataset. In the training dataset a better detection rate was observed for enlarged LNs compared to smaller LNs, the detection rate for LNs with a short-axis diameter (SAD) ≥ 20 mm and SAD 5–10 mm being 91.6% and 62.2% (p < 0.001), respectively. Best detection rates were obtained for LNs located in Level 4R (83.6%) and Level 7 (80.4%). Conclusions: The proposed 3D deep learning approach achieves an overall good performance in the automatic detection and segmentation of thoracic LNs and shows reasonable generalizability, yielding the potential to facilitate detection during routine clinical work and to enable radiomics research without observer-bias. © 2021, The Author(s).","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85104291492"
"Zhou Z.; Siddiquee M.M.R.; Tajbakhsh N.; Liang J.","Zhou, Zongwei (57201419561); Siddiquee, Md Mahfuzur Rahman (57215777586); Tajbakhsh, Nima (25655631900); Liang, Jianming (7404541897)","57201419561; 57215777586; 25655631900; 7404541897","UNet++: Redesigning Skip Connections to Exploit Multiscale Features in Image Segmentation","2020","IEEE Transactions on Medical Imaging","39","6","8932614","1856","1867","11","2183","10.1109/TMI.2019.2959609","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084466306&doi=10.1109%2fTMI.2019.2959609&partnerID=40&md5=416207d62eb8df74f323b9cbcfbc5d16","The state-of-the-art models for medical image segmentation are variants of U-Net and fully convolutional networks (FCN). Despite their success, these models have two limitations: (1) their optimal depth is apriori unknown, requiring extensive architecture search or inefficient ensemble of models of varying depths; and (2) their skip connections impose an unnecessarily restrictive fusion scheme, forcing aggregation only at the same-scale feature maps of the encoder and decoder sub-networks. To overcome these two limitations, we propose UNet++, a new neural architecture for semantic and instance segmentation, by (1) alleviating the unknown network depth with an efficient ensemble of U-Nets of varying depths, which partially share an encoder and co-learn simultaneously using deep supervision; (2) redesigning skip connections to aggregate features of varying semantic scales at the decoder sub-networks, leading to a highly flexible feature fusion scheme; and (3) devising a pruning scheme to accelerate the inference speed of UNet++. We have evaluated UNet++ using six different medical image segmentation datasets, covering multiple imaging modalities such as computed tomography (CT), magnetic resonance imaging (MRI), and electron microscopy (EM), and demonstrating that (1) UNet++ consistently outperforms the baseline models for the task of semantic segmentation across different datasets and backbone architectures; (2) UNet++ enhances segmentation quality of varying-size objects - an improvement over the fixed-depth U-Net; (3) Mask RCNN++ (Mask R-CNN with UNet++ design) outperforms the original Mask R-CNN for the task of instance segmentation; and (4) pruned UNet++ models achieve significant speedup while showing only modest performance degradation. Our implementation and pre-trained models are available at https://github.com/MrGiovanni/UNetPlusPlus. © 1982-2012 IEEE.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-85084466306"
"Guilenea F.N.; Casciaro M.E.; Soulat G.; Mousseaux E.; Craiem D.","Guilenea, Federico N (57217171377); Casciaro, Mariano E (23049285600); Soulat, Gilles (54780655700); Mousseaux, Elie (56261678400); Craiem, Damian (6602770358)","57217171377; 23049285600; 54780655700; 56261678400; 6602770358","Automatic thoracic aorta calcium quantification using deep learning in non-contrast ECG-gated CT images","2024","Biomedical Physics and Engineering Express","10","3","035007","","","","1","10.1088/2057-1976/ad2ff2","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187621797&doi=10.1088%2f2057-1976%2fad2ff2&partnerID=40&md5=a4f58fc22754c12297f77881db9c7770","Thoracic aorta calcium (TAC) can be assessed from cardiac computed tomography (CT) studies to improve cardiovascular risk prediction. The aim of this study was to develop a fully automatic system to detect TAC and to evaluate its performance for classifying the patients into four TAC risk categories. The method started by segmenting the thoracic aorta, combining three UNets trained with axial, sagittal and coronal CT images. Afterwards, the surrounding lesion candidates were classified using three combined convolutional neural networks (CNNs) trained with orthogonal patches. Image datasets included 1190 non-enhanced ECG-gated cardiac CT studies from a cohort of cardiovascular patients (age 57 ± 9 years, 80% men, 65% TAC > 0). In the test set (N = 119), the combination of UNets was able to successfully segment the thoracic aorta with a mean volume difference of 0.3 ± 11.7 ml (<6%) and a median Dice coefficient of 0.947. The combined CNNs accurately classified the lesion candidates and 87% of the patients (N = 104) were accurately placed in their corresponding risk categories (Kappa = 0.826, ICC = 0.9915). TAC measurement can be estimated automatically from cardiac CT images using UNets to isolate the thoracic aorta and CNNs to classify calcified lesions. © 2024 IOP Publishing Ltd.","Article","Final","","Scopus","2-s2.0-85187621797"
"Gavrilov P.V.; Smolnikova U.A.","Gavrilov, Pavel V. (12776018900); Smolnikova, Uliana A. (57209658597)","12776018900; 57209658597","Evaluation of diagnostic accuracy of the automatic system for the analysis of digital lung X-ray for detection of spherical masses","2021","Almanac of Clinical Medicine","49","6","","359","364","5","0","10.18786/2072-0505-2021-49-035","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162932820&doi=10.18786%2f2072-0505-2021-49-035&partnerID=40&md5=2c08d0bff0b31689bc2faaee153bf852","Rationale: Most data on the effectiveness of systems for the analysis of digital X-ray images have been provided by their developers and require a high-quality validation in databases prepared independently of the developer. Aim: To analyze the information content of automatic identification of spherical lung masses with digital X-ray imaging using one of the widely available diagnostic algorithms on publicly unaccessible reference datasets. Materials and methods: The study was based on the recognition and analysis of digital X-ray images from two publicly inaccessible reference datasets that have the state registration (Russian Federation) with one of the publicly available diagnostic algorithms (FutureMed Analyzer). The study was performed using two models of X-ray screening as examples: Model 1 consisted of 100 X-ray images of the lungs with a normal: abnormal ratio of 94%: 6%; Model 2 consisted of 5150 chest X-ray images with a normal: abnormal ratio of 97%: 3%. Results: According to the results of the analysis of the X-ray images with the diagnostic system, 98% of the images were correctly interpreted with Model 1 and 95% of the images, with Model 2. 83% of the cases from Model 1 and 69% from Model 2% were interpreted as images with lung abnormalities. The percentage of correct answers for differentiation of the chest X-ray images into two categories (normal vs. abnormal) for Model 1 and Model 2 was 95% and 98%, respectively. The sensitivity for detection of abnormal masses ranged from 69% to 83%. The specificity was 99% for the Model 1 chest X-ray images and 96% for the Model 2 chest X-ray images. The underdiagnosis rate was quite low ranging for Model 1 – 17%, and for Model 2 – 31%. The area under the curve for Model 1 was 0.91 and for Model 2 0.85. Conclusion: The diagnostic efficiency of the automatic image analysis based on the convolutional neuronal networks approaches that of the radiologists. This system of automatic identification of abnormalities was unable to solve the most complex problems of detecting low density spherical masses (like ""ground glass"" area on computed tomography) and that of shadow summation for abnormalities located in such difficult to interpret zones as lung apices, clavicles, ribs, etc. To select a suitable system, medical institutions need to conduct preliminary testing in their own models equivalent to the studies performed in a given institution (parameters for radiography, nature and frequency of abnormalities). © 2021, Moscow Regional Research and Clinical Institute. All rights reserved.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85162932820"
"Dullin C.; Missbach-Guentner J.; Vogel W.F.; Grabbe E.; Alves F.","Dullin, Christian (15724937900); Missbach-Guentner, Jeannine (15726251400); Vogel, Wolfgang F. (57203194473); Grabbe, Eckhardt (7102305343); Alves, Frauke (7005934184)","15724937900; 15726251400; 57203194473; 7102305343; 7005934184","Semi-automatic classification of skeletal morphology in genetically altered mice using flat-panel volume computed tomography","2007","PLoS Genetics","3","7","","1232","1243","11","18","10.1371/journal.pgen.0030118","https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547646382&doi=10.1371%2fjournal.pgen.0030118&partnerID=40&md5=411879d6d4fb2ca2fb48e8ba3b1921a7","Rapid progress in exploring the human and mouse genome has resulted in the generation of a multitude of mouse models to study gene functions in their biological context. However, effective screening methods that allow rapid noninvasive phenotyping of transgenic and knockout mice are still lacking. To identify murine models with bone alterations in vivo, we used flat-panel volume computed tomography (fpVCT) for high-resolution 3-D imaging and developed an algorithm with a computational intelligence system. First, we tested the accuracy and reliability of this approach by imaging discoidin domain receptor 2- (DDR2-) deficient mice, which display distinct skull abnormalities as shown by comparative landmark-based analysis. High-contrast fpVCT data of the skull with 200 lm isotropic resolution and 8-s scan time allowed segmentation and computation of significant shape features as well as visualization of morphological differences. The application of a trained artificial neuronal network to these datasets permitted a semiautomatic and highly accurate phenotype classification of DDR2-deficient compared to C57BL/6 wild-type mice. Even heterozygous DDR2 mice with only subtle phenotypic alterations were correctly determined by fpVCT imaging and identified as a new class. In addition, we successfully applied the algorithm to classify knockout mice lacking the DDR1 gene with no apparent skull deformities. Thus, this new method seems to be a potential tool to identify novel mouse phenotypes with skull changes from transgenic and knockout mice on the basis of random mutagenesis as well as from genetic models. However for this purpose, new neuronal networks have to be created and trained. In summary, the combination of fpVCT images with artificial neuronal networks provides a reliable, novel method for rapid, costeffective, and noninvasive primary screening tool to detect skeletal phenotypes in mice. © 2007 Dullin et al.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-34547646382"
"Stroebel J.; Horng A.; Armbruster M.; Mittone A.; Reiser M.; Bravin A.; Coan P.","Stroebel, Johannes (57218792753); Horng, Annie (16031008900); Armbruster, Marco (55771078900); Mittone, Alberto (55453700600); Reiser, Maximilian (36050187000); Bravin, Alberto (7003905715); Coan, Paola (6701464571)","57218792753; 16031008900; 55771078900; 55453700600; 36050187000; 7003905715; 6701464571","Convolutional neuronal networks combined with X-ray phase-contrast imaging for a fast and observer-independent discrimination of cartilage and liver diseases stages","2020","Scientific Reports","10","1","20007","","","","5","10.1038/s41598-020-76937-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096142525&doi=10.1038%2fs41598-020-76937-y&partnerID=40&md5=43189831a61c11dab9d15db1069535a6","We applied transfer learning using Convolutional Neuronal Networks to high resolution X-ray phase contrast computed tomography datasets and tested the potential of the systems to accurately classify Computed Tomography images of different stages of two diseases, i.e. osteoarthritis and liver fibrosis. The purpose is to identify a time-effective and observer-independent methodology to identify pathological conditions. Propagation-based X-ray phase contrast imaging WAS used with polychromatic X-rays to obtain a 3D visualization of 4 human cartilage plugs and 6 rat liver samples with a voxel size of 0.7 × 0.7 × 0.7 µm3 and 2.2 × 2.2 × 2.2 µm3, respectively. Images with a size of 224 × 224 pixels are used to train three pre-trained convolutional neuronal networks for data classification, which are the VGG16, the Inception V3, and the Xception networks. We evaluated the performance of the three systems in terms of classification accuracy and studied the effect of the variation of the number of inputs, training images and of iterations. The VGG16 network provides the highest classification accuracy when the training and the validation-test of the network are performed using data from the same samples for both the cartilage (99.8%) and the liver (95.5%) datasets. The Inception V3 and Xception networks achieve an accuracy of 84.7% (43.1%) and of 72.6% (53.7%), respectively, for the cartilage (liver) images. By using data from different samples for the training and validation-test processes, the Xception network provided the highest test accuracy for the cartilage dataset (75.7%), while for the liver dataset the VGG16 network gave the best results (75.4%). By using convolutional neuronal networks we show that it is possible to classify large datasets of biomedical images in less than 25 min on a 8 CPU processor machine providing a precise, robust, fast and observer-independent method for the discrimination/classification of different stages of osteoarthritis and liver diseases. © 2020, The Author(s).","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85096142525"
